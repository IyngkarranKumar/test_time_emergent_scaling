#data 
dataset_name: math-ai/aime25
#workflow scale parameters
num_samples: 4
batch_size: 4
num_completions: 3
solution_set_batch_size: 20
vllm_gpu_memory_utilization: 0.8
max_model_len: None #sets to last token budget size + buffer

#model
model_name: Qwen/Qwen2.5-0.5B-Instruct
quantization: 8 #defaults to fp16

#workflow 
start_token_budget: 10 #log2
end_token_budget: 10 #log2

#SAVE
SAVE_BOOL: False
TIME_BASED_SAVING: True
save_every_n_mins: 60

#inference
inference_engine: "vllm"
max_new_tokens_frac: 0.125

#scoring 
normalise_over_solution_set: True

#debug
DEBUG_MODE: False

