#use this as scoring debug - gsm8k is easy even for small-ish models


#data 
dataset_name: "Maxwell-Jia/AIME_2024"
num_samples: 4
batch_size: 4
num_completions: 1


#model
model_name: "Qwen/Qwen2.5-3B-Instruct"
quantization: None #defaults to fp16

#workflow 
start_token_budget: 7 #log2
end_token_budget: 7 #log2

#SAVE
SAVE_BOOL: False

#inference
inference_engine: "hf"
max_new_tokens_frac: 0.25
vllm_gpu_memory_utilization: 0.9

#scoring 
normalise_over_solution_set: True
solution_set_batch_size: 80

#debug
DEBUG_MODE: False